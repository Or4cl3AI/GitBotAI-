import pickle
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import LinearSVC
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
import nltk
from nltk.corpus import stopwords
import json
import os

class NLUModel:
    def __init__(self):
        self.model = None
        self.intents = None
        self.load_model()

    def load_model(self):
        if os.path.exists('nlu_model.pkl'):
            with open('nlu_model.pkl', 'rb') as file:
                self.model = pickle.load(file)
        else:
            self.train_model()

        with open('intents.json') as file:
            self.intents = json.load(file)

    def train_model(self):
        nltk.download('stopwords')
        stop_words = set(stopwords.words('english'))

        with open('intents.json') as file:
            data = json.load(file)

        X = []
        y = []
        for intent in data['intents']:
            for pattern in intent['patterns']:
                X.append(pattern)
                y.append(intent['tag'])

        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        self.model = Pipeline([
            ('tfidf', TfidfVectorizer(stop_words=stop_words)),
            ('clf', LinearSVC())
        ])

        self.model.fit(X_train, y_train)

        y_pred = self.model.predict(X_test)

        print(classification_report(y_test, y_pred))

        with open('nlu_model.pkl', 'wb') as file:
            pickle.dump(self.model, file)

    def predict_intent(self, text):
        return self.model.predict([text])[0]

    def get_response(self, intent):
        for i in self.intents['intents']:
            if i['tag'] == intent:
                return random.choice(i['responses'])

        return None
```
